{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import interpolation as inter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_skew(image, delta=1, limit=5):\n",
    "    def determine_score(arr, angle):\n",
    "        data = inter.rotate(arr, angle, reshape=False, order=0)\n",
    "        histogram = np.sum(data, axis=1)\n",
    "        score = np.sum((histogram[1:] - histogram[:-1]) ** 2)\n",
    "        return histogram, score\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1] \n",
    "\n",
    "    scores = []\n",
    "    angles = np.arange(-limit, limit + delta, delta)\n",
    "    for angle in angles:\n",
    "        histogram, score = determine_score(thresh, angle)\n",
    "        scores.append(score)\n",
    "\n",
    "    best_angle = angles[scores.index(max(scores))]\n",
    "\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, best_angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, \\\n",
    "              borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    return best_angle, rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_image):\n",
    "    image = cv2.imread(input_image)\n",
    "    #Converting the colored image to greyscale\n",
    "    angle, rotated = correct_skew(image)\n",
    "    print(angle)\n",
    "    cv2.imwrite('rotated.jpg', rotated)\n",
    "    gray = cv2.cvtColor(rotated,cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    # Remove horizontal lines\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40,1))\n",
    "    remove_horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "    cnts = cv2.findContours(remove_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        cv2.drawContours(rotated, [c], -1, (255,255,255), 5)\n",
    "        # Remove vertical lines\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,40))\n",
    "    remove_vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
    "    cnts = cv2.findContours(remove_vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        cv2.drawContours(rotated, [c], -1, (255,255,255), 5)\n",
    "    gray = cv2.cvtColor(rotated,cv2.COLOR_BGR2GRAY)\n",
    "    #applying median filter for Salt and pepper/impulse noise\n",
    "    filter1 = cv2.medianBlur(gray,5)\n",
    "    #applying gaussian blur to smoothen out the image edges\n",
    "    filter2 = cv2.GaussianBlur(filter1,(5,5),0)\n",
    "    #applying non-localized means for final Denoising of the image\n",
    "    dst = cv2.fastNlMeansDenoising(filter2,None,17,9,17)\n",
    "    #converting the image to binarized form using adaptive thresholding\n",
    "    th1 = cv2.adaptiveThreshold(dst,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    return th1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cmp_to_key\n",
    "def contour_sort(a, b):\n",
    "\n",
    "    br_a = cv2.boundingRect(a)\n",
    "    br_b = cv2.boundingRect(b)\n",
    "\n",
    "    if abs(br_a[1] - br_b[1]) <= 20:\n",
    "        return br_a[0] - br_b[0]\n",
    "\n",
    "    return br_a[1] - br_b[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contour_distance(contour1, contour2): \n",
    "    x1, y1, w1, h1 = cv2.boundingRect(contour1)\n",
    "    c_x1 = x1 + w1/2\n",
    "    c_y1 = y1 + h1/2\n",
    "\n",
    "    x2, y2, w2, h2 = cv2.boundingRect(contour2)\n",
    "    c_x2 = x2 + w2/2\n",
    "    c_y2 = y2 + h2/2\n",
    "\n",
    "    return max(abs(c_x1 - c_x2) - (w1 + w2)/2, abs(c_y1 - c_y2) - (h1 + h2)/2)\n",
    "\n",
    "def merge_contours(contour1, contour2):\n",
    "    return np.concatenate((contour1, contour2), axis=0)\n",
    "\n",
    "def agglomerative_cluster(contours, threshold_distance=0.5):\n",
    "    current_contours = contours\n",
    "    while len(current_contours) > 1:\n",
    "        min_distance = None\n",
    "        min_coordinate = None\n",
    "\n",
    "        for x in range(len(current_contours)-1):\n",
    "            for y in range(x+1, len(current_contours)):\n",
    "                distance = calculate_contour_distance(current_contours[x], current_contours[y])\n",
    "                if min_distance is None:\n",
    "                    min_distance = distance\n",
    "                    min_coordinate = (x, y)\n",
    "                elif distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    min_coordinate = (x, y)\n",
    "\n",
    "        if min_distance < threshold_distance:\n",
    "            index1, index2 = min_coordinate\n",
    "            current_contours[index1] = merge_contours(current_contours[index1], current_contours[index2])\n",
    "            del current_contours[index2]\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    return current_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segement will take the preprocessed image as input and return the segmented image\n",
    "\n",
    "def segment(image):\n",
    "    gray = cv2.GaussianBlur(image, (7, 7), 0)\n",
    "    ret,thresh1 = cv2.threshold(gray ,127,255,cv2.THRESH_BINARY_INV)\n",
    "    dilate = cv2.dilate(thresh1, None, iterations=2)\n",
    "    cnts,_ = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # sorted_ctrs = sorted(cnts, key=lambda ctr: cv2.boundingRect(ctr)[0] + cv2.boundingRect(ctr)[1] * image.shape[1] )\n",
    "    sorted_ctrs = sorted(cnts, key=cmp_to_key(contour_sort))\n",
    "    sorted_ctrs = agglomerative_cluster(sorted_ctrs)\n",
    "    orig = cv2.merge([image,image,image])\n",
    "    i = 0\n",
    "    for cnt in sorted_ctrs:\n",
    "        # Check the area of contour, if it is very small ignore it\n",
    "        if(cv2.contourArea(cnt) < 200):\n",
    "            continue\n",
    "\n",
    "        # Filtered countours are detected\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        \n",
    "        # Taking ROI of the cotour\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Mark them on the image if you want\n",
    "        cv2.rectangle(orig,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "        copy_img = cv2.merge([image,image,image])\n",
    "        cv2.rectangle(copy_img,(x,y),(x+w,y+h),(0,255,0),4)\n",
    "        \n",
    "\n",
    "        # Save your contours or characters\n",
    "        cv2.imwrite( r\"./individual/\"+str(i) + \".png\", roi)\n",
    "        cv2.imwrite( r\"./test_individual/\"+str(i) + \".png\", copy_img)\n",
    "    \n",
    "        i = i + 1\n",
    "    return orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty ./test_individual folder and ./individual folder\n",
    "for filename in os.listdir('./test_individual'):\n",
    "    os.remove('./test_individual/'+filename)\n",
    "for filename in os.listdir('./individual'):\n",
    "    os.remove('./individual/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adeel\\AppData\\Local\\Temp\\ipykernel_11116\\3330985539.py:3: DeprecationWarning: Please use `rotate` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  data = inter.rotate(arr, angle, reshape=False, order=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_image=segment(preprocess('21.jpg'))\n",
    "# save the segmented image\n",
    "cv2.imwrite('segmented.jpg', segmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
